{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M0mo_0zmAfn3"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"fKEUL6umBsOX"},"source":["###Import TensorFlow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mvFa9ArOBvCn"},"outputs":[],"source":["import tensorflow as tf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIZ2n9a3Bwh2"},"outputs":[],"source":["\n","#You can use wget to download the file directly\n","!wget http://www.manythings.org/anki/hin-eng.zip --quiet\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KvMYs2agBxgf"},"outputs":[],"source":["\n","!ls -l\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jOKniId-ByXA"},"outputs":[],"source":["\n","#Unzip\n","!unzip hin-eng.zip\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4F_NvvxBzJ-"},"outputs":[],"source":["\n","!ls -l\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXbD7e5hBz23"},"outputs":[],"source":["\n","!cat hin.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tji96nULChJY"},"outputs":[],"source":["import zipfile\n","import io\n","\n","#Read the zip file\n","zf = zipfile.ZipFile('hin-eng.zip', 'r')\n","\n","#Extract data from zip file\n","data = ''\n","with zf.open('hin.txt') as readfile:\n","    for line in io.TextIOWrapper(readfile, 'utf-8'):\n","        data += line"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x5isruSgCz-f"},"outputs":[],"source":["len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4S4bBB8mC8Pv"},"outputs":[],"source":["print(data[40000:50000])"]},{"cell_type":"markdown","metadata":{"id":"kMlGj5TnC0d_"},"source":["###Extract source and target language pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUpeV5iYCpGA"},"outputs":[],"source":["data= data.split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtEiOiYQCsWu"},"outputs":[],"source":["len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UdVN0K3FCt3f"},"outputs":[],"source":["#show data\n","data[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EbJWhKSuB1bG"},"outputs":[],"source":["encoder_text = [] #Initialize Source language list\n","decoder_text = [] #Initialize Target language list\n","\n","#Iterate over data\n","for line in data:\n","    try:\n","        in_txt, out_txt, _ = line.split('\\t')\n","        encoder_text.append(in_txt)\n","\n","        # Add tab '<start>' as start sequence in target\n","        # And '<end>' as End\n","        decoder_text.append('<start> ' + out_txt + ' <end>')\n","    except:\n","        pass #ignore data which goes into error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZORnk1axCcuH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"i5X984XVDGXf"},"source":["### Seperate Source and Target pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HAsQunU8DJop"},"outputs":[],"source":["#English(Source)\n","encoder_text[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xg50WTCWDO7_"},"outputs":[],"source":["#Target Language\n","decoder_text[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nnLmw1N9DZBf"},"outputs":[],"source":["len(encoder_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUZMWJ35DbA_"},"outputs":[],"source":["len(decoder_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tn_HQYl-DsM2"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"wv8L7HWnDzqQ"},"source":["### Tokenize Source Language Sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lKdlnH0yEKXH"},"outputs":[],"source":["#Tokenizer for source language\n","encoder_t = tf.keras.preprocessing.text.Tokenizer(lower=True)\n","encoder_t.fit_on_texts(encoder_text) #Fit it on Source sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b1gsBXn5EPl4"},"outputs":[],"source":["#Vocab\n","len(encoder_t.word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eeu28W4BEPow"},"outputs":[],"source":["print(encoder_t.word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4HbtT8uERZ_"},"outputs":[],"source":["#Convert English text to indexes\n","encoder_seq = encoder_t.texts_to_sequences(encoder_text) #Convert sentences to numbers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSJlnZTXERcx"},"outputs":[],"source":["encoder_text[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6tJlyzdEPrn"},"outputs":[],"source":["encoder_seq[100:105] #Display some converted sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpNEheoMEVeP"},"outputs":[],"source":["#Maximum length of sentence\n","max_encoder_seq_length = max((len(txt) for txt in encoder_seq))\n","print('Maximum sentence length for Source language: ', max_encoder_seq_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w_xYrEFGEbRX"},"outputs":[],"source":["#Source language Vocablury\n","encoder_vocab_size = len(encoder_t.word_index)\n","print('Source language vocablury size: ', encoder_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-y6XD4qaD2PC"},"outputs":[],"source":["\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6FxO7J7aE0an"},"source":["## Tokenize Target Language Sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJ-crracE5Uj"},"outputs":[],"source":["#Tokenizer for target language, filters should not <start> and <end>\n","#remove < and > used in Target language sequences\n","decoder_t = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')  ## these filters are same as default ones except < and > as its part of our data\n","decoder_t.fit_on_texts(decoder_text) #Fit it on Target sentences\n","decoder_seq = decoder_t.texts_to_sequences(decoder_text) #Convert sentences to numbers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOAAQp0MFAMQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiL7c3GeE-6w"},"outputs":[],"source":["print(decoder_t.word_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iffT0hoEE-Rf"},"outputs":[],"source":["decoder_text[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMcWWrjgE9fw"},"outputs":[],"source":["decoder_seq[100:105]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMC9GFw5E82I"},"outputs":[],"source":["#Maximum length of sentence\n","max_decoder_seq_length = max((len(txt) for txt in decoder_seq))\n","print('Maximum sentence length for Target language: ', max_decoder_seq_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JLE3Vw4PE8AX"},"outputs":[],"source":["\n","#Target language Vocablary\n","decoder_vocab_size = len(decoder_t.word_index)\n","print('Target language vocablury size: ', decoder_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ID7gGn1pFuYp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"DzTmGiX8FvAY"},"source":["### Compare"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-OWEwhAFw2Y"},"outputs":[],"source":["#Source Language sentences\n","print('Length for sentence number 100: ', len(encoder_seq[100]))\n","print('Length for sentence number 150: ', len(encoder_seq[150]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J01Tc_DzFx_f"},"outputs":[],"source":["\n","#Target Language sentences\n","print('Length for sentence number 100: ', len(decoder_seq[100]))\n","print('Length for sentence number 150: ', len(decoder_seq[150]))"]},{"cell_type":"markdown","metadata":{"id":"yXq653WGF8bf"},"source":["### best way to make all the sentences of same size , is to pick the length of biggest sentence , 22 for eng and 27 for hindi"]},{"cell_type":"markdown","metadata":{"id":"pZSC3XYyEsHh"},"source":["### Padding sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vafdik2kF7r-"},"outputs":[],"source":["\n","\n","#Source sentences\n","encoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(encoder_seq,\n","                                                                   maxlen=max_encoder_seq_length,\n","                                                                   padding='pre')\n","\n","#Target Sentences\n","decoder_input_data = tf.keras.preprocessing.sequence.pad_sequences(decoder_seq,\n","                                                                   maxlen=max_decoder_seq_length,\n","                                                                   padding='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qGa2Vg3GWSJ"},"outputs":[],"source":["print('Source data shape: ', encoder_input_data.shape)\n","print('Target data shape: ', decoder_input_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TPThAocEGhxw"},"outputs":[],"source":["encoder_text[100]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBFX7BINGh0Y"},"outputs":[],"source":["encoder_input_data[100]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaE_IflTGh3A"},"outputs":[],"source":["decoder_text[100]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmFViZEbGEHG"},"outputs":[],"source":["decoder_input_data[100]"]},{"cell_type":"markdown","metadata":{"id":"7glxPW6DFDO6"},"source":[]},{"cell_type":"markdown","metadata":{"id":"rUpGEhWaE1HR"},"source":["##Integer to word converter for Decoder data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfoQdj1ZE5GP"},"outputs":[],"source":["int_to_word_decoder = dict((i,c) for c, i in decoder_t.word_index.items())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CoT4f39qb7sY"},"outputs":[],"source":["print(int_to_word_decoder)"]},{"cell_type":"markdown","metadata":{"id":"uLj_yfH6cAp3"},"source":["### Building Decoder ouput\n"," - here we are preparing expected output in the format of the model output so that loss can be calculated"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2T-ephyceng"},"outputs":[],"source":["decoder_input_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCMU1glFcCok"},"outputs":[],"source":["# drop the start tag at the begining of the expected output\n","#<start> yeh kitab hai <end>  ####### this format is converted to below one because that is the output of the model\n","#Yeh kitab hai <end> 0\n","\n","# we started with a empty array and looped through decoder input data and shifted it by one word to lose start tag\n","import numpy as np\n","\n","#Initialize array\n","decoder_target_data = np.zeros((decoder_input_data.shape[0],\n","                                decoder_input_data.shape[1]))\n","\n","#Shift Target output by one word\n","for i in range(decoder_input_data.shape[0]):\n","    for j in range(1,decoder_input_data.shape[1]):\n","        decoder_target_data[i][j-1] = decoder_input_data[i][j]\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYAaGaLpckPX"},"outputs":[],"source":["#decoder_t.word_index\n","\n","#<start> yeh kitab hai <end>\n","#Yeh kitab hai <end> 0\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOM6YmGwcl4_"},"outputs":[],"source":["decoder_text[0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j7k6H1-Xcmw3"},"outputs":[],"source":["\n","decoder_input_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWO_CvX3dPB3"},"outputs":[],"source":["decoder_target_data[1]"]},{"cell_type":"markdown","metadata":{"id":"Vaf3NXLPdoT3"},"source":["\n","###Convert target data in one hot vector\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_1iY1oodqmo"},"outputs":[],"source":["\n","#Initialize one hot encoding array\n","decoder_target_one_hot = np.zeros(((decoder_input_data.shape[0], #Number of sentences\n","decoder_input_data.shape[1], #Number of words in each sentence\n","len(decoder_t.word_index)+1))) #Vocab size + 1\n","\n","decoder_target_one_hot.shape\n","\n","#Build one hot encoded array\n","for i in range(decoder_target_data.shape[0]):\n","  for j in range(decoder_target_data.shape[1]):\n","    decoder_target_one_hot[i][j] = tf.keras.utils.to_categorical(decoder_target_data[i][j],\n","                                                                                num_classes=len(decoder_t.word_index)+1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ei3mp8aHd3Co"},"outputs":[],"source":["decoder_target_one_hot.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1Wgoqn1d_hw"},"outputs":[],"source":["## First Example\n","decoder_target_one_hot[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrxP12RAeC3e"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"I5n10EqUeGOn"},"source":["### Building The Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_9ZCkcNjeIZq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-3S9Y1v1egPD"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"pDjDKF1uDvsb"},"source":["###Define config parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUldlZ-HesDX"},"outputs":[],"source":["encoder_embedding_size = 80\n","decoder_embedding_size = 80\n","rnn_units = 100 #Memory size for LSTM - both endcoder and decoder need to have the same memory size\n"]},{"cell_type":"markdown","metadata":{"id":"vwFSiP8MDyHL"},"source":["###Build Encoder\n"]},{"cell_type":"markdown","metadata":{"id":"-W2oRWYBEAED"},"source":["####tf.keras.backend.clear_session() is a function in TensorFlow/Keras that is used to clear the current TensorFlow graph and release any memory it might be holding."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6yKbadLD8XL"},"outputs":[],"source":["tf.keras.backend.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHEAW45MD1m9"},"outputs":[],"source":["\n","\n","#Input Layer\n","encoder_inputs = tf.keras.layers.Input(shape=(22,)) # Maximum sentence length for Source language is   22 which is the input hence the input shape\n","\n","#Embedding Layer - Word2Vec\n","encoder_embedding = tf.keras.layers.Embedding(encoder_vocab_size+1, #Size for One hot encoding\n","encoder_embedding_size) #How many numbers to use for each word\n","\n","#Get embedding layer output by feeding inputs\n","encoder_embedding_output = encoder_embedding(encoder_inputs)\n","\n","#LSTM Layer and its output\n","x, state_h, state_c = tf.keras.layers.LSTM(rnn_units, return_state=True, dropout=0.2, recurrent_dropout=0.3)(encoder_embedding_output)\n","#  - when return_sequences=False which is by default in keras: x= state_h == sentence embedding\n","#  - return_state=True: because we want both c and h\n","#  - dropout=0.2: apply 20% dropout before LSTM layer\n","#  - recurrent_dropout=0.2 : apply 30% after LSTM layer\n","\n","#Build a list to feed Decoder - Sentence Embedding\n","encoder_states = [state_h, state_c]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UyybZ318Fb18"},"outputs":[],"source":["encoder_embedding_output  # [22,50] i.e. there are 22 words and each word is convered to 50 numbers embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tb4h5aQXD5dl"},"outputs":[],"source":["encoder_states  # each example is converted to 128 number/features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJRQNXLNEMNt"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_G_-fz9NGnu9"},"source":["### Build Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aVBC2oG-GpTk"},"outputs":[],"source":["\n","# Decoder input - padded Target sentences\n","decoder_inputs = tf.keras.layers.Input(shape=(27,)) # Maximum sentence length for Target language:  27\n","\n","# Embedding layer\n","decoder_embedding = tf.keras.layers.Embedding(decoder_vocab_size + 1,\n","    decoder_embedding_size)\n","\n","# Embedding layer output\n","decoder_embedding_output = decoder_embedding(decoder_inputs)\n","\n","# Decoder rnn\n","decoder_rnn = tf.keras.layers.LSTM(rnn_units, dropout=0.2,\n","                                    recurrent_dropout=0.3,\n","                                    return_sequences=True,\n","                                    return_state=True)\n","\n","  # - when return_sequences=True:\n","  # - all_hidden_states_d: all outputs from all time steps → shape (batch_size, time_steps, 128)\n","  # - last_hidden_state_d: still the final hidden state → shape (batch_size, 128)\n","\n","# Decoder RNN Output, takes two params: output of embedding layer and the ouput of decoder as cell and hidden states\n","all_hidden_states_d,last_hidden_state_d,last_cell_state_d = decoder_rnn(decoder_embedding_output,\n","    initial_state=encoder_states)\n","\n","#Output Layer : 3048 probabilites will be ouput here\n","decoder_dense = tf.keras.layers.Dense(decoder_vocab_size + 1, #+1 to make sure one-hot encoding works for highest index value\n","    activation='softmax')\n","\n","#Output of Dense layer\n","decoder_outputs = decoder_dense(all_hidden_states_d)"]},{"cell_type":"markdown","metadata":{"id":"SmS28lkiNY27"},"source":["###Build Model using both Encoder and Decoder\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JxCDM0_NcBK"},"outputs":[],"source":["\n","#Build a Seq2Seq model -> Encoder + Decoder\n","model = tf.keras.models.Model([encoder_inputs, decoder_inputs], #Inputs to the model\n","decoder_outputs) #Output of the model\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"jv2fLcnZNi-S"},"source":["###Train the model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sur7bJ7yNkVC"},"outputs":[],"source":["model.fit([encoder_input_data, decoder_input_data],\n","decoder_target_one_hot,\n","batch_size=64,\n","epochs=10,\n","validation_split=0.2)"]},{"cell_type":"markdown","metadata":{"id":"mEY8BL-CNdG6"},"source":["###Save the model for later reuse"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OSX37l8NeRH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"rDx4fiDlP1pK"},"source":["###Building Model for Prediction\n","\n","####Build the Encoder Model to predict Encoder States\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBVy8WwNP6ZR"},"outputs":[],"source":["encoder_model = tf.keras.Model(encoder_inputs,encoder_states) #Padded input sequences\n"," #Hidden state and Cell state at last time step\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MiThnxwdQjWD"},"outputs":[],"source":["encoder_model.summary()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_XU5py0QkNz"},"outputs":[],"source":["encoder_model.output"]},{"cell_type":"markdown","metadata":{"id":"td6P8fz0QiCz"},"source":["###Build the Decoder Model\n","\n","* Define Input for both 'h' state and 'c' state initialization\n","* Get Decoder RNN outputs along with h and c state\n","* Get Decoder Dense layer output\n","* Build Model\n"]},{"cell_type":"markdown","metadata":{"id":"UcYRvzZmQozU"},"source":["####Step 1 - Define Input for both 'h' state and 'c' state initialization\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C3Bn0ESIQng0"},"outputs":[],"source":["#Hidden state input\n","decoder_state_input_h = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Cell state input\n","decoder_state_input_c = tf.keras.layers.Input(shape=(rnn_units,))\n","\n","#Putting it together\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n"]},{"cell_type":"markdown","metadata":{"id":"h5EpPmlDQ02M"},"source":["####Step 2 - Get Decoder RNN outputs along with h and c state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ucsvx_9Q1pl"},"outputs":[],"source":["#Get Embedding layer output\n","x = decoder_embedding(decoder_inputs)\n","\n","#We will use the layer which we trained earlier\n","rnn_outputs, state_h, state_c = decoder_rnn(x, initial_state=decoder_states_inputs)\n","\n","#Why do we need this?\n","decoder_states = [state_h, state_c]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0ylIJSFRAYc"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Q6rzmej4RLws"},"source":["\n","####Step 3 - Get Decoder Dense layer output\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riKIuSKqRNEj"},"outputs":[],"source":["decoder_outputs = decoder_dense(rnn_outputs)"]},{"cell_type":"markdown","metadata":{"id":"e0Rq6Z4pRPCj"},"source":["####Step 4 - Build Decoder Model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2wTlNnURcEw"},"outputs":[],"source":["decoder_model = tf.keras.models.Model([decoder_inputs] + decoder_states_inputs, #Model inputs\n","                                      [decoder_outputs] + decoder_states)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VviVRFjtRgED"},"outputs":[],"source":["decoder_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"h-CSQ0MNSPns"},"source":["###Predicting output from Seq2Seq model\n","\n","####Build a prediction function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yg88EdASRQx"},"outputs":[],"source":["decoder_t.word_index['<start>']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"se5rLnFOSTTb"},"outputs":[],"source":["int_to_word_decoder[51]"]},{"cell_type":"markdown","metadata":{"id":"y9G71mAhSqX6"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aR_mrp3ZTHrU"},"outputs":[],"source":["def decode_sentence(input_sequence):\n","    #Get the encoder state values - Sentence embedding\n","    decoder_initial_states_value = encoder_model.predict(input_seq)\n","    # print (\"this is the input seq from encoder: \", decoder_initial_states_value)\n","    #Build a sequence with '<start>' - starting sequence for Decoder\n","    target_seq = np.zeros(((1,1)))\n","    target_seq[0][0] = decoder_t.word_index['<start>']\n","\n","    #flag to check if prediction should be stopped\n","    stop_loop = False\n","\n","    #Initialize predicted sentence\n","    predicted_sentence = ''\n","\n","    num_of_predictions = 0\n","\n","    #start the loop\n","    while not stop_loop:\n","\n","        predicted_outputs, h, c = decoder_model.predict([target_seq] +\n","                                                    decoder_initial_states_value)\n","        #Get the predicted word index with highest probability\n","        predicted_output = np.argmax(predicted_outputs[0, -1,:])\n","\n","        #Get the predicted word from predictor index\n","        predicted_word = int_to_word_decoder[predicted_output]\n","\n","        #Check if prediction should stop\n","        if(predicted_word == '<end>' or num_of_predictions > max_decoder_seq_length):\n","            stop_loop = True\n","            continue\n","\n","        num_of_predictions += 1\n","        #Updated predicted sentence\n","        if (len(predicted_sentence) == 0):\n","            predicted_sentence = predicted_word\n","        else:\n","            predicted_sentence = predicted_sentence + ' ' + predicted_word\n","\n","        #Update target_seq to be the predicted word index\n","        target_seq[0][0] = predicted_output\n","\n","        #Update initial states value for decoder\n","        decoder_initial_states_value = [h,c]\n","\n","    return predicted_sentence"]},{"cell_type":"markdown","metadata":{"id":"KyJRyvpbTv-r"},"source":["###Call Prediction Function on a random sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S40w3b4nTziw"},"outputs":[],"source":["#Generate a random number\n","start_num = np.random.randint(0, high=len(encoder_text) - 10)\n","\n","#Predict model output for 5 sentences\n","for i in range(start_num, start_num + 5):\n","    input_seq = encoder_input_data[i : i+1]\n","    predicted_sentence = decode_sentence(input_seq)\n","    print('----------')\n","    print('Input sentence: ', encoder_text[i])\n","    print('Predicted sentence: ', predicted_sentence)"]},{"cell_type":"markdown","metadata":{"id":"jDFyXuHvUBkT"},"source":["### save encoder and decoder models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjcQp0dvUD5T"},"outputs":[],"source":["#Compile models to avoid error\n","encoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","decoder_model.compile(optimizer='adam',loss='categorical_crossentropy')\n","\n","#Save the models\n","encoder_model.save('seq2seq_encoder_eng_hin.h5') #Encoder model\n","decoder_model.save('seq2seq_decoder_eng_hin.h5') #Decoder model"]},{"cell_type":"markdown","metadata":{"id":"0nuHefNWUyME"},"source":["### Save encoder and decoder tokenizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-IXEwaiUySz"},"outputs":[],"source":["\n","import pickle\n","\n","\n","pickle.dump(encoder_t,open('encoder_tokenizer_eng','wb'))\n","pickle.dump(decoder_t,open('decoder_tokenizer_hin','wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9hZYiqggq4N"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyO6EMxn+U9XBU6M5A+GWJ7k"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}