{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPAEkMv9FQP0gmXJoYpBsGz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"re9RJn3lLad_"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["---\n","\n","# Summary of Key Generation Parameters\n","\n","```python\n","do_sample=True,    # Enable sampling instead of greedy decoding (randomness in output)\n","temperature=0.9,   # Controls randomness/creativity of sampling (less than 1 makes output more focused)\n","top_p=0.9          # Nucleus sampling: only sample from tokens comprising top 90% cumulative probability\n","```\n","\n","when using do_Sample , we need to use other two : top_p and temprature\n","\n","---\n","\n","### What these settings do:\n","\n","* **do\\_sample=True**\n","  This means the model will **pick words randomly** instead of always picking the most likely word. This makes the responses more interesting and varied.\n","\n","* **temperature=0.9**\n","  This controls how random the model’s choices are.\n","\n","  * If the number is close to 0, the model picks very safe and common words.\n","  * If it’s higher (like above 1), it gets more creative and random.\n","  * 0.9 means it’s a little less random than usual, so the output is mostly clear but still a bit creative.\n","\n","* **top\\_p=0.9**\n","  The model looks at all possible next words, sorts them by how likely they are, and picks from the top 90% of total probability.\n","  This helps the model avoid weird or very unlikely words while still giving some variety.\n","\n","---\n","\n","### How they work together:\n","\n","1. The model figures out which words are possible next.\n","2. It makes those choices a bit less or more random based on **temperature**.\n","3. It only picks from the most likely words (the top 90%) because of **top\\_p**.\n","4. It then **randomly** chooses a word from that filtered list because of **do\\_sample=True**.\n","\n","---\n","\n","This way, the chatbot doesn’t always say the same thing but still makes sense.\n"],"metadata":{"id":"7ipyT535Lbti"}},{"cell_type":"code","source":[],"metadata":{"id":"pUATmP9YLccm"},"execution_count":null,"outputs":[]}]}