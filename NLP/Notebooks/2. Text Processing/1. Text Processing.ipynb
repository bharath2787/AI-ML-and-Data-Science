{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"dVJ8LqgK1Q4w"},"source":["# Handling HTML Text"]},{"cell_type":"markdown","metadata":{"id":"fvWZv6joy5OX"},"source":["We can use Beautiful Soup package to clean Web data"]},{"cell_type":"code","metadata":{"id":"K87WWgtuGIcL"},"source":["from bs4 import BeautifulSoup"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install BeautifulSoup"],"metadata":{"id":"6aH_-3P-__v0"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Xit3_ckwyS9"},"source":["def strip_html_tags(text):\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    stripped_text = soup.get_text()\n","    return stripped_text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This Python function, `strip_html_tags`, removes HTML tags from a given text, leaving only the plain text content. Here's a breakdown of the code:\n","\n","1. **`def strip_html_tags(text):`**\n","\n","   * This line defines a function named `strip_html_tags` that takes a single argument `text`, which is expected to be a string containing HTML content.\n","\n","2. **`soup = BeautifulSoup(text, \"html.parser\")`**\n","\n","   * The `BeautifulSoup` class is imported from the `bs4` (BeautifulSoup) library, which is used to parse HTML or XML documents.\n","   * The `text` is passed to `BeautifulSoup`, and the \"html.parser\" specifies that the HTML content in `text` should be parsed using Python's built-in HTML parser.\n","   * `soup` is now a BeautifulSoup object representing the HTML structure of the input string.\n","\n","3. **`stripped_text = soup.get_text()`**\n","\n","   * The `get_text()` method of the BeautifulSoup object extracts the text content from the parsed HTML, removing all the HTML tags. It returns a plain text string with just the human-readable content, leaving out the tags, script contents, and other HTML elements.\n","\n","4. **`return stripped_text`**\n","\n","   * Finally, the function returns the `stripped_text`, which is the original content from the `text` argument but without any HTML tags.\n"],"metadata":{"id":"Vnjry8n8y9Yo"}},{"cell_type":"code","metadata":{"id":"-N7tQ6vT7Dur"},"source":["strip_html_tags('<html><h2>Some important text</h2></html>')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["strip_html_tags('''<span class=\"a-size-base\">IOS 17.5 (current version updated from 16.6)<br>Thw worst thing as a ios user for me that the fear of update , i heared some updates get display issues battery drain issues , god sake i doesn't had any issues from ios updates , but till i care<br>- device  was great, super handy for me, little feeling of weight .<br>Display<br> - The 60Hz refresh rate didn't felt badly form me cause i am used such kind of device before.<br> - The brightness Range is so comfortable.<br> - The 2160p60 HDR videos in youtube give blissful experiance<br>Battery And charging<br> - The charging time:- i took 1Hour to charge  from 20% to 91% using apple 20w original adapter and cable without any interruption(no electricity break or disconnection ,calls etc)<br> - Battery backup - I am mostly maintain battery in btw 20% &lt;-&gt; 80% so i think this may get one day backup for me ,Average 5h screen on time<br>The one day backup is just a advertisemnt advertisement label usaully we use, actually a day like  events,party,outing  we use -camera ,editing app, social media app more than usual use , that day i didn't get a satisfied backup .<br> - Little temperature warming while charging , no heating issue<br>- battery health after 6 month 98%<br>-battery cycle count 194  after 6 month<br>Perfomance<br> - Good perfomance for video editing ,photography , social media . (I am not a gamer )<br> Camera<br>-  Even though i  felt some lag or stuck screens in some third party applications<br> - The cinematic Mode is mind Blowing . i missed 13 pro or higher varients for zooming in this mode .<br> - Actually i really miss pro variant for the tele lens and camera features while i using this . Cost is wall for me.<br> - The photos are nice and feature like exposure adjust and filter was good and quality photos . And the 5x zoomed photos is not good for me.it reduced the pixel quality .<br>- The video and optical image stabilisation was mind blowing . i mostly explore on videos . it was soo good , no words other than that.<br>AND THE BIGGEST FEAR FOR ME NOW IS IOS UPDATE<br>i turned off the auto update at first place .<br>i heared about DISPLAY ISSUES,HEATING ISSUES and BUGS in the ios updates for 13 and 14 series.<br>So for expencive and established brand like apple does not fair . This is the only -ve i have to say as a reminder .Also i heared without ios update display issues are happened . Buy the way it is a hardware issue one of the display provider company's batch may show the issues . but we customers cannot identify which company provides the hardaware.<br>I will attach my battery analytics data screnshot photo here so you can better understand how the battery is good<br> The ordering experience in the greate indian sale was worst . I planned to buy this for 45999/- in oct7 greate indian sale offer but i got canceled then i bought for 48999 that was disppointed .<br>As a whole i didn't recommend base models ,i felt i must have buy pro variant but for person who need ios in affordable price i recommend 13 is better than 14</span>''')"],"metadata":{"id":"S7kj37-QAdwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NBK3ZgwUwySt"},"source":["# Removing Special Characters"]},{"cell_type":"markdown","source":["* The function `remove_special_characters` removes special characters from a string using regex.\n","* If `remove_digits` is `False` (default), it keeps letters, digits, and spaces, and removes other characters.\n","* If `remove_digits` is `True`, it removes digits as well, leaving only letters and spaces. It uses `re.sub` to replace matching characters with an empty string.\n"],"metadata":{"id":"OqlBMyi_zovP"}},{"cell_type":"markdown","source":["The `re` part in the code refers to the use of Python's `re` module, which provides support for working with regular expressions.\n","\n","* **`re.sub(pattern, '', text)`**: This function searches for patterns (defined by `pattern`) in the `text` and replaces them with an empty string (`''`), effectively removing them.\n","* **`pattern = r'[^a-zA-Z0-9\\s]'`**: This regular expression matches any character that is **not** a letter (A-Z, a-z), digit (0-9), or whitespace (`\\s`).\n","* **`pattern = r'[^a-zA-Z\\s]'`**: If `remove_digits=True`, this pattern removes characters that are **not** a letter or whitespace, excluding digits.\n"],"metadata":{"id":"PdrceuPHzlnn"}},{"cell_type":"code","metadata":{"id":"xrEY5j6rzQ3k"},"source":["import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCmBJeI5wyTN"},"source":["def remove_special_characters(text, remove_digits=False):\n","    #Using regex\n","    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n","    text = re.sub(pattern, '', text)\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9IGXQ-LwyTQ"},"source":["remove_special_characters(\"Well this was fun! What do you think? 123#@!\", remove_digits=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVHrzwoEU0rK"},"source":["remove_special_characters('S√≥mƒõ √Åccƒõntƒõd tƒõxt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HBbRSoPkwyTB"},"source":["# Remove accented characters"]},{"cell_type":"markdown","source":["The function `remove_accented_chars` removes accented characters from a string, leaving only the non-accented characters. Here's how it works:\n","\n","### Breakdown:\n","\n","```python\n","text = unicodedata.normalize('NFKD', text)\n","```\n","\n","* **`unicodedata.normalize('NFKD', text)`**:\n","\n","  * This normalizes the text to the **NFKD** (Normalization Form KD) form, where accented characters are decomposed into their base character and accent.\n","  * For example, \"√©\" becomes \"e\" and \"ÃÅ\" (the accent) is separated from it.\n","\n","```python\n",".encode('ascii', 'ignore')\n","```\n","\n","* **`.encode('ascii', 'ignore')`**:\n","\n","  * This encodes the normalized text into ASCII, ignoring any non-ASCII characters (like accents).\n","  * After this step, characters like \"√©\" are removed since they cannot be represented in ASCII.\n","\n","```python\n",".decode('utf-8', 'ignore')\n","```\n","\n","* **`.decode('utf-8', 'ignore')`**:\n","\n","  * This decodes the ASCII bytes back into a UTF-8 string, effectively converting the remaining characters (without accents) back into a string.\n","\n","### Final Output:\n","\n","The function returns a string without any accented characters, leaving only the non-accented versions.\n","\n"],"metadata":{"id":"nLOW4hW5z-wn"}},{"cell_type":"code","metadata":{"id":"XIjJTyTsziU_"},"source":["import unicodedata"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TOBdIlTWwyTB"},"source":["def remove_accented_chars(text):\n","    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edyaT3Yn7XsP"},"source":["remove_accented_chars('S√≥mƒõ √Åccƒõntƒõd tƒõxt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ryt_VSOVwyTT"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Text Lemmatization"]},{"cell_type":"code","metadata":{"id":"tPQmV8DiJJF1"},"source":["import nltk\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The code snippet is using the **Natural Language Toolkit (NLTK)**, a Python library for working with human language data (text). Here's an explanation of each part:\n","\n","### `import nltk`\n","\n","* **`import nltk`**: This imports the NLTK library into your Python script, allowing you to use its functionalities for tasks like tokenization, stemming, lemmatization, and more.\n","\n","### `nltk.download('punkt')`\n","\n","* **`nltk.download('punkt')`**: This downloads the **Punkt tokenizer models**, which are used for splitting text into sentences or words (tokenization). Tokenization is a key step in many NLP tasks.\n","\n","  * The 'punkt' package contains pre-trained models for various languages to identify sentence and word boundaries.\n","\n","### `nltk.download('wordnet')`\n","\n","* **`nltk.download('wordnet')`**: This downloads the **WordNet lexical database**, which is used for tasks like **lemmatization**. WordNet groups English words into sets of synonyms (synsets) and provides semantic relationships between words, such as antonyms or hyponyms.\n","\n","  * By downloading WordNet, you can use NLTK functions to look up meanings, synonyms, and relationships between words.\n","\n","### Summary:\n","\n","* `nltk.download('punkt')` is for tokenization, helping split text into sentences or words.\n","* `nltk.download('wordnet')` is for working with the WordNet database, used for lemmatization and understanding word meanings and relationships.\n"],"metadata":{"id":"MkpthdEC0Yuo"}},{"cell_type":"code","metadata":{"id":"tXQNHEHpJKdf"},"source":["from nltk.stem import WordNetLemmatizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uNR0fNT4wyTU"},"source":["def lemmatize_text(text):\n","\n","    lemmatizer = WordNetLemmatizer()\n","    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"My system keeps crashing, his crashed yesterday, ours crashes daily\".split()"],"metadata":{"id":"GgyzZi7BW1Xl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\".\".join([\"a\",\"b\"])"],"metadata":{"id":"hvtvmOQ3W8y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"do-LTxKRwyTX"},"source":["lemmatize_text(\"My system keeps crashing, his crashed yesterday, ours crashes daily\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jWmDYl9swyTa"},"source":["# Text Stemming"]},{"cell_type":"code","metadata":{"id":"wcgdJFzLwyTb"},"source":["def simple_stemmer(text):\n","    ps = nltk.porter.PorterStemmer()\n","    text = ' '.join([ps.stem(word) for word in text.split()])\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7q1Ke6-z0LO"},"source":["simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NZkucc1TmrLk"},"source":["# Working with Emojis"]},{"cell_type":"code","metadata":{"id":"NhJ0wQa1mdqe"},"source":["!pip install emoji --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmgT5exTnJ1p"},"source":["import emoji"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwqblltmmUqB"},"source":["#input data\n","input_text = 'He is üò≥'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsrHV054mlgN"},"source":["#Replace emoji icon with text\n","output_text = emoji.demojize(input_text)\n","output_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUY1z27mnd57"},"source":["#Remove ':' from emoji text\n","output_text = output_text.replace(':','')\n","output_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q_yVIMV9D1P6"},"execution_count":null,"outputs":[]}]}