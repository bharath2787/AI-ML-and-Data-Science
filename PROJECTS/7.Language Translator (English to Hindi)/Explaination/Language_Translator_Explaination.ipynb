{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJZtjyFP1sXUOdvF/x4kGr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_qYE_I04edhT"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["\n","---\n","\n","## **Capstone Project: English-to-Hindi Language Translator using Seq2Seq LSTM**\n","\n","As part of my AIML certification program, I completed a hands-on capstone project where I designed and developed an **English-to-Hindi language translator** using a **Sequence-to-Sequence (Seq2Seq) model with LSTM** architecture. The goal of the project was to apply NLP techniques to build a working machine translation pipeline and deploy it through a user-friendly web interface.\n","\n","---\n","\n","###  **Tech Stack & Tools Used**\n","\n","* **Programming & ML Libraries:** Python, TensorFlow, Keras, NumPy\n","* **UI Framework:** Streamlit\n","* **Dataset:** Tatoeba English-Hindi sentence pairs (sourced from [manythings.org](http://www.manythings.org/anki/))\n","* **Others:** Zip handling, Tokenizers, Pickle for saving models and preprocessing tools\n","\n","---\n","\n","### ðŸ’¡ **Problem Statement**\n","\n","Translate English sentences into grammatically correct and contextually appropriate Hindi sentences using neural networks, simulating how Google Translate works at a basic level.\n","\n","---\n","\n","###  **Project Workflow & Implementation**\n","\n","#### 1. **Data Collection and Preprocessing**\n","\n","* Downloaded a parallel corpus of English-Hindi sentence pairs.\n","* Cleaned and parsed the data, creating two datasets: English (source) and Hindi (target).\n","* Added special tokens (`<start>`, `<end>`) to target sequences to signal the start and end of decoding.\n","* Tokenized both source and target languages using Keras Tokenizers and padded them to the maximum sentence length.\n","\n","#### 2. **Model Architecture**\n","\n","* **Encoder:**\n","\n","  * Used an embedding layer followed by an LSTM layer that outputs internal states (hidden and cell).\n","  * These states serve as the initial context for the decoder.\n","\n","* **Decoder:**\n","\n","  * Takes the previous word (starting with `<start>`) and generates the next word at each time step.\n","  * Also uses its own embedding and LSTM layers.\n","  * The output is passed through a Dense layer with a softmax activation to predict the most likely next word.\n","  * Trained using **categorical crossentropy loss** and **one-hot encoded labels**.\n","\n","#### 3. **Training & Optimization**\n","\n","* Trained on padded sequences using `model.fit()` with a batch size of 64 for 20 epochs.\n","* Used 20% of the data for validation.\n","* Achieved reasonable performance for short and medium-length sentences.\n","\n","#### 4. **Inference Model Setup**\n","\n","* Split the trained model into separate **encoder** and **decoder** models for prediction.\n","* Implemented a **greedy decoding** function to iteratively predict Hindi translations one word at a time until the `<end>` token or max length is reached.\n","\n","#### 5. **Deployment with Streamlit**\n","\n","* Built a clean and interactive web interface using Streamlit.\n","* The UI allows users to input English sentences and receive live Hindi translations from the trained model.\n","* Behind the scenes, the input sentence is tokenized, encoded, passed through the model, and decoded back to Hindi text.\n","\n","---\n","\n","###  **Outcomes**\n","\n","* Developed a fully functional translation model capable of generating basic Hindi sentences from English input.\n","* Successfully demonstrated the encoder-decoder architecture and how LSTM networks handle sequence-to-sequence tasks.\n","* Learned how to bridge the gap between ML models and end-user interaction via web apps.\n","\n","---\n","\n","###  **Key Takeaways**\n","\n","* Gained practical exposure to core NLP concepts: text vectorization, sequence padding, embeddings, RNNs, and decoding strategies.\n","* Understood the importance of preparing separate training and inference models for real-time predictions.\n","* Learned to handle model saving/loading and tokenizers for production use.\n","* Developed UI/UX thinking while integrating ML models into an interactive front-end using Streamlit.\n","\n","---\n","\n","###  **How to Present This in an Interview**\n","\n","> \"In my final AIML capstone, I built an English-to-Hindi translator using a Sequence-to-Sequence LSTM model. I started by preparing the bilingual dataset, tokenizing and padding the sequences. I trained an encoder-decoder architecture where the encoder creates context vectors, and the decoder uses them to generate the translated sentence word by word. I then set up separate encoder and decoder inference models for prediction and deployed the system using a Streamlit web app. This helped me understand the end-to-end ML pipelineâ€”from data prep and model building to real-time inference and deployment.\"\n","\n","---\n","\n"],"metadata":{"id":"NWPtDNdteeVA"}},{"cell_type":"code","source":[],"metadata":{"id":"FYeZCtsUeuP8"},"execution_count":null,"outputs":[]}]}