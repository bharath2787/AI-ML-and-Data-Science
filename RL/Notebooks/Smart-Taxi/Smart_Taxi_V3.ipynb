{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM65TYynCnv/oJbJ0catXen"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##**Smart Taxi** : https://gymnasium.farama.org/environments/toy_text/taxi/"],"metadata":{"id":"-a7tuf2UxgTK"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"p1hb-Q2i9Cz4","executionInfo":{"status":"ok","timestamp":1750734865998,"user_tz":-330,"elapsed":8866,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"90c26aee-528a-4281-aa39-cfb3bbe42728"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n"]}],"source":["!pip install numpy==1.23.5  # install this and restart notebook to fix the issue with gym library"]},{"cell_type":"code","source":["!pip install gym==0.25.2\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQvmGETu9DWL","executionInfo":{"status":"ok","timestamp":1750734873135,"user_tz":-330,"elapsed":7129,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"ccfbdef8-d626-4f7e-a274-b74cce817b80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gym==0.25.2 in /usr/local/lib/python3.11/dist-packages (0.25.2)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.25.2) (1.23.5)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.25.2) (3.1.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.25.2) (0.0.8)\n"]}]},{"cell_type":"code","source":["# Importing necessary libraries\n","import gym        # OpenAI Gym for RL environments\n","import numpy as np\n","import pickle, os\n","\n"],"metadata":{"id":"YP4XLak89DZs","executionInfo":{"status":"ok","timestamp":1750734873380,"user_tz":-330,"elapsed":242,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(\"Gym version:\", gym.__version__)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_t8GjvcF3Pd","executionInfo":{"status":"ok","timestamp":1750734873642,"user_tz":-330,"elapsed":255,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"9b027ca3-137c-465e-ff79-5b7690177ff6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Gym version: 0.25.2\n"]}]},{"cell_type":"code","source":["# Create the Taxi environment from OpenAI Gym\n","env = gym.make(\"Taxi-v3\")"],"metadata":{"id":"M19uFxxk9mKE","executionInfo":{"status":"ok","timestamp":1750734873658,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e90e7e70-71e6-4127-c9fe-d7f0ad0f83b1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["# Reset the environment and get the initial state - it will randomly pick a state\n","state = env.reset()\n","\n"],"metadata":{"id":"rr7ZQhmt9k1E","executionInfo":{"status":"ok","timestamp":1750734873961,"user_tz":-330,"elapsed":303,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["state # look at the state generated : this will initialize taxi at a random state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIkGflbj1Xm5","executionInfo":{"status":"ok","timestamp":1750734873966,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"89dc3583-44d1-4b9b-f263-4f5fe91e6fbe"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["212"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Show the total number of states (500 in Taxi-v3)\n","env.observation_space.n\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hxb4ggC9jW-","executionInfo":{"status":"ok","timestamp":1750734873970,"user_tz":-330,"elapsed":3,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"fcf9ac64-577d-43c8-e881-0e730f1ad510"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Render the initial grid — taxi environment with walls, pickup/drop points\n","print(env.render(mode=\"ansi\"))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1PeDM7vX9ibH","executionInfo":{"status":"ok","timestamp":1750734873974,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"b8a8535b-65e9-4244-8996-5707b701545f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","|\u001b[43m \u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  deprecation(\n"]}]},{"cell_type":"code","source":["# There are 6 possible actions in Taxi-v3:\n","# 0: South, 1: North, 2: East, 3: West, 4: Pickup, 5: Drop-off\n","n_states = env.observation_space.n\n","n_actions = env.action_space.n\n","\n","n_actions  # Will output 6\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTkm14Iq9hWb","executionInfo":{"status":"ok","timestamp":1750734874034,"user_tz":-330,"elapsed":59,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"74c655d7-16dc-4184-f44f-72a376435825"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# You can also manually set a specific environment state for demo\n","env.env.s = 300\n","print(env.render(mode=\"ansi\"))\n","\n","# BLUE = PICKUP LOCATIOM\n","# PINK = DROP LOCATION"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9TCtnxMJ9gE0","executionInfo":{"status":"ok","timestamp":1750734874039,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"371a9c10-c945-4168-c052-2981d8540abb"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","|\u001b[43m \u001b[0m: : : : |\n","| | : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","\n","\n"]}]},{"cell_type":"markdown","source":["###Actions:\n","* 0: Move south (down)\n","\n","* 1: Move north (up)\n","\n","* 2: Move east (right)\n","\n","* 3: Move west (left)\n","\n","* 4: Pickup passenger\n","\n","* 5: Drop off passenger"],"metadata":{"id":"oojlN5pE2EKy"}},{"cell_type":"code","source":["# Take actions manually to see how the taxi behaves\n","env.step(0)   # Move south\n","print(env.render(mode=\"ansi\"))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUSYUrzd9ePd","executionInfo":{"status":"ok","timestamp":1750734880947,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"26c1404a-7487-43cb-f119-05c1dbcb7caf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","|\u001b[43m \u001b[0m| : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (South)\n","\n"]}]},{"cell_type":"code","source":["env.step(2)   # Move east\n","print(env.render(mode=\"ansi\"))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSU3TPPCMVg9","executionInfo":{"status":"ok","timestamp":1750734890933,"user_tz":-330,"elapsed":13,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"fb0b5104-a794-4556-b66d-0b4fc8fe41d6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","|\u001b[43m \u001b[0m| : | : |\n","|Y| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (East)\n","\n"]}]},{"cell_type":"code","source":["env.step(0)   # Move south again\n","print(env.render(mode=\"ansi\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c4ZPDv6xMWsO","executionInfo":{"status":"ok","timestamp":1750734898097,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"97381252-aeaa-4afe-e80d-f8c93cdc384f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|\u001b[35mR\u001b[0m: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[43mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (South)\n","\n"]}]},{"cell_type":"code","source":["# Let's try a random action and observe the outcome\n","env.step(env.action_space.sample())\n","\n","\n","# output is of the format : (next_state, reward, done, info)\n","# each of these parameters are explained below"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Ng1nMmr9dI1","executionInfo":{"status":"ok","timestamp":1750735514140,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"928861d1-e9f8-4e7e-901d-43301b78110a"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(85,\n"," -10,\n"," True,\n"," {'prob': 1.0,\n","  'action_mask': array([1, 0, 0, 1, 1, 0], dtype=int8),\n","  'TimeLimit.truncated': True})"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["\n","###  Interpretation:\n","#### 1. `447` → **Next State**\n","\n","* This is the encoded state **number**. In `Taxi-v3`, the state is a single integer (from 0 to 499) that encodes the taxi’s:\n","\n","  * Row (5 possible)\n","  * Column (5 possible)\n","  * Passenger location (5 possible: at 4 locations or in the taxi)\n","  * Destination (4 possible)\n","* So, `447` is just a state ID.\n","\n","#### 2. `-1` → **Reward**\n","\n","* The environment penalizes each step with **-1** until the passenger is successfully dropped at the destination.\n","* This encourages the agent to find the **shortest path**.\n","\n","#### 3. `False` → **Done**\n","\n","* `False` means the episode is **not yet finished**.\n","* It would be `True` only when the taxi successfully picks up the passenger and drops them at the correct destination.\n","\n","#### 4. `{'prob': 1.0, 'action_mask': array([0, 1, 0, 1, 0, 0], dtype=int8)}` → **Info Dictionary**\n","\n","* This extra dictionary gives **metadata** about the environment transition.\n","\n","Let's look into both keys:\n","\n","##### a. `'prob': 1.0`\n","\n","* The **probability** of the transition happening is 1.0.\n","* Taxi is a **deterministic** environment, so the result of any action is always the same (no randomness).\n","\n","##### b. `'action_mask': array([0, 1, 0, 1, 0, 0])`\n","\n","* This shows which **actions are currently allowed**.\n","\n","* In `Taxi-v3`, there are **6 possible actions**:\n","\n","  ```\n","  0 = south\n","  1 = north\n","  2 = east\n","  3 = west\n","  4 = pickup\n","  5 = dropoff\n","  ```\n","\n","* The mask `[0, 1, 0, 1, 0, 0]` means:\n","\n","  * Action 1 (north) and 3 (west) are **allowed** (`1`)\n","  * Others are **not allowed** (`0`)\n","  * For example, if the taxi is not at the passenger location, `pickup` (4) is invalid and masked out.\n","\n","---\n","\n","###  Why is `action_mask` Useful?\n","\n","* It's helpful when using agents that need to know which actions are legal (e.g., in **masked reinforcement learning**).\n","* Prevents trying invalid moves like pickup when no passenger is there.\n","\n","---\n","\n","###  Summary\n","\n","The output means:\n","\n","* After taking an action, you're now in state `447`\n","* You got a penalty of `-1`\n","* The episode is not done yet\n","* You can only take actions `north` and `west` next\n","\n"],"metadata":{"id":"QA1E4Hy45Nvr"}},{"cell_type":"code","source":[],"metadata":{"id":"Opr2TMg49oHn","executionInfo":{"status":"ok","timestamp":1750735514580,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["### just for testing purpose:\n"," - we are dropping the taxi at a random location and leaving it to converge\n"," - at the end we will count the number of step and reward"],"metadata":{"id":"isLPr_NU9aRA"}},{"cell_type":"code","source":["# ----------------------------------------------\n","# 🔍 Test: How well does a random agent perform?\n","# ----------------------------------------------\n","\n","state = env.reset()\n","counter = 0\n","tot_reward = 0\n","reward = None\n"],"metadata":{"id":"jFpoEkTc9auU","executionInfo":{"status":"ok","timestamp":1750735515093,"user_tz":-330,"elapsed":11,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Run until we get the max reward of 20 (i.e., successful drop-off)\n","while reward != 20:\n","    state, reward, done, info = env.step(env.action_space.sample())  # Random action\n","    counter += 1\n","    tot_reward += reward\n","\n","print(\"Solved in {} Steps with a Total Reward of {}\".format(counter, tot_reward))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_WQ4_Km9Zcd","executionInfo":{"status":"ok","timestamp":1750735515475,"user_tz":-330,"elapsed":66,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"99cfc933-06c0-4b3e-e34e-72457b91b5d5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Solved in 1370 Steps with a Total Reward of -5597\n"]}]},{"cell_type":"code","source":["# As seen above in such problem it is unlikely we will get a positive cummulative reward"],"metadata":{"id":"OFcrNYU_95Uo","executionInfo":{"status":"ok","timestamp":1750735515836,"user_tz":-330,"elapsed":42,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Using the above logic we just need to add an extra step to update Q-Matrix as shown below"],"metadata":{"id":"q7uJkNHI-GvY","executionInfo":{"status":"ok","timestamp":1750735516639,"user_tz":-330,"elapsed":12,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["\n","# ----------------------------------------------\n","# ✅ Q-Learning Implementation\n","# ----------------------------------------------\n","\n","# Initialize Q-table with all zeros (states × actions)\n","Q = np.zeros([n_states, n_actions])\n","\n","Q.shape  # (500, 6) for Taxi-v3\n","\n","episodes = 1000      # Number of training episodes\n","G = 0                # Total cumulative reward\n","gamma = 0.7          # Discount factor (how much future reward matters)\n","\n","# Loop over episodes to train the agent\n","for episode in range(1, episodes + 1):\n","    done = False\n","    G, reward = 0, 0\n","    state = env.reset()\n","    firststate = state\n","    print(\"Initial State = {} \".format(state))\n","\n","    # Run until successful drop-off (reward == 20)\n","    while reward != 20:\n","        # Choose best known action (greedy)\n","        action = np.argmax(Q[state])\n","        # Take the action and observe the outcome\n","        state2, reward, done, info = env.step(action)\n","        # Update Q-table using Q-learning update rule (off-policy)\n","        Q[state, action] += gamma * (reward + np.max(Q[state2]) - Q[state, action])\n","        G += reward\n","        state = state2\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJ2FA0an9W2t","executionInfo":{"status":"ok","timestamp":1750735518605,"user_tz":-330,"elapsed":1139,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"6810563a-c51b-4f97-c203-d245c853a1e8"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial State = 389 \n","Initial State = 153 \n","Initial State = 364 \n","Initial State = 241 \n","Initial State = 86 \n","Initial State = 86 \n","Initial State = 31 \n","Initial State = 472 \n","Initial State = 348 \n","Initial State = 53 \n","Initial State = 368 \n","Initial State = 329 \n","Initial State = 193 \n","Initial State = 251 \n","Initial State = 341 \n","Initial State = 303 \n","Initial State = 21 \n","Initial State = 49 \n","Initial State = 267 \n","Initial State = 91 \n","Initial State = 152 \n","Initial State = 208 \n","Initial State = 108 \n","Initial State = 61 \n","Initial State = 81 \n","Initial State = 191 \n","Initial State = 166 \n","Initial State = 294 \n","Initial State = 22 \n","Initial State = 122 \n","Initial State = 146 \n","Initial State = 364 \n","Initial State = 326 \n","Initial State = 486 \n","Initial State = 148 \n","Initial State = 324 \n","Initial State = 492 \n","Initial State = 154 \n","Initial State = 189 \n","Initial State = 173 \n","Initial State = 103 \n","Initial State = 51 \n","Initial State = 314 \n","Initial State = 429 \n","Initial State = 428 \n","Initial State = 208 \n","Initial State = 226 \n","Initial State = 473 \n","Initial State = 89 \n","Initial State = 381 \n","Initial State = 363 \n","Initial State = 407 \n","Initial State = 34 \n","Initial State = 149 \n","Initial State = 388 \n","Initial State = 462 \n","Initial State = 266 \n","Initial State = 111 \n","Initial State = 86 \n","Initial State = 486 \n","Initial State = 69 \n","Initial State = 474 \n","Initial State = 274 \n","Initial State = 69 \n","Initial State = 391 \n","Initial State = 49 \n","Initial State = 211 \n","Initial State = 449 \n","Initial State = 21 \n","Initial State = 434 \n","Initial State = 306 \n","Initial State = 493 \n","Initial State = 33 \n","Initial State = 472 \n","Initial State = 91 \n","Initial State = 284 \n","Initial State = 368 \n","Initial State = 263 \n","Initial State = 126 \n","Initial State = 466 \n","Initial State = 491 \n","Initial State = 486 \n","Initial State = 411 \n","Initial State = 11 \n","Initial State = 432 \n","Initial State = 43 \n","Initial State = 153 \n","Initial State = 148 \n","Initial State = 134 \n","Initial State = 228 \n","Initial State = 88 \n","Initial State = 386 \n","Initial State = 222 \n","Initial State = 186 \n","Initial State = 9 \n","Initial State = 361 \n","Initial State = 387 \n","Initial State = 122 \n","Initial State = 388 \n","Initial State = 288 \n","Initial State = 362 \n","Initial State = 414 \n","Initial State = 34 \n","Initial State = 221 \n","Initial State = 294 \n","Initial State = 431 \n","Initial State = 47 \n","Initial State = 84 \n","Initial State = 66 \n","Initial State = 221 \n","Initial State = 29 \n","Initial State = 31 \n","Initial State = 101 \n","Initial State = 493 \n","Initial State = 288 \n","Initial State = 461 \n","Initial State = 12 \n","Initial State = 329 \n","Initial State = 344 \n","Initial State = 91 \n","Initial State = 149 \n","Initial State = 241 \n","Initial State = 349 \n","Initial State = 403 \n","Initial State = 269 \n","Initial State = 53 \n","Initial State = 349 \n","Initial State = 103 \n","Initial State = 334 \n","Initial State = 266 \n","Initial State = 226 \n","Initial State = 291 \n","Initial State = 389 \n","Initial State = 71 \n","Initial State = 103 \n","Initial State = 121 \n","Initial State = 367 \n","Initial State = 293 \n","Initial State = 454 \n","Initial State = 82 \n","Initial State = 389 \n","Initial State = 1 \n","Initial State = 367 \n","Initial State = 491 \n","Initial State = 66 \n","Initial State = 223 \n","Initial State = 366 \n","Initial State = 494 \n","Initial State = 246 \n","Initial State = 106 \n","Initial State = 172 \n","Initial State = 23 \n","Initial State = 321 \n","Initial State = 363 \n","Initial State = 4 \n","Initial State = 342 \n","Initial State = 267 \n","Initial State = 466 \n","Initial State = 432 \n","Initial State = 313 \n","Initial State = 6 \n","Initial State = 228 \n","Initial State = 452 \n","Initial State = 449 \n","Initial State = 481 \n","Initial State = 272 \n","Initial State = 164 \n","Initial State = 29 \n","Initial State = 221 \n","Initial State = 203 \n","Initial State = 481 \n","Initial State = 14 \n","Initial State = 493 \n","Initial State = 403 \n","Initial State = 332 \n","Initial State = 292 \n","Initial State = 333 \n","Initial State = 384 \n","Initial State = 228 \n","Initial State = 331 \n","Initial State = 263 \n","Initial State = 429 \n","Initial State = 421 \n","Initial State = 369 \n","Initial State = 374 \n","Initial State = 231 \n","Initial State = 111 \n","Initial State = 488 \n","Initial State = 282 \n","Initial State = 487 \n","Initial State = 6 \n","Initial State = 326 \n","Initial State = 141 \n","Initial State = 4 \n","Initial State = 332 \n","Initial State = 363 \n","Initial State = 322 \n","Initial State = 386 \n","Initial State = 49 \n","Initial State = 84 \n","Initial State = 472 \n","Initial State = 411 \n","Initial State = 192 \n","Initial State = 227 \n","Initial State = 369 \n","Initial State = 43 \n","Initial State = 88 \n","Initial State = 62 \n","Initial State = 121 \n","Initial State = 187 \n","Initial State = 171 \n","Initial State = 311 \n","Initial State = 432 \n","Initial State = 226 \n","Initial State = 123 \n","Initial State = 301 \n","Initial State = 493 \n","Initial State = 244 \n","Initial State = 366 \n","Initial State = 466 \n","Initial State = 427 \n","Initial State = 174 \n","Initial State = 301 \n","Initial State = 244 \n","Initial State = 309 \n","Initial State = 463 \n","Initial State = 363 \n","Initial State = 189 \n","Initial State = 68 \n","Initial State = 463 \n","Initial State = 194 \n","Initial State = 204 \n","Initial State = 228 \n","Initial State = 104 \n","Initial State = 68 \n","Initial State = 384 \n","Initial State = 222 \n","Initial State = 424 \n","Initial State = 192 \n","Initial State = 264 \n","Initial State = 282 \n","Initial State = 287 \n","Initial State = 393 \n","Initial State = 372 \n","Initial State = 233 \n","Initial State = 412 \n","Initial State = 134 \n","Initial State = 48 \n","Initial State = 366 \n","Initial State = 87 \n","Initial State = 368 \n","Initial State = 411 \n","Initial State = 51 \n","Initial State = 481 \n","Initial State = 493 \n","Initial State = 282 \n","Initial State = 72 \n","Initial State = 352 \n","Initial State = 251 \n","Initial State = 28 \n","Initial State = 328 \n","Initial State = 53 \n","Initial State = 491 \n","Initial State = 189 \n","Initial State = 229 \n","Initial State = 141 \n","Initial State = 431 \n","Initial State = 169 \n","Initial State = 462 \n","Initial State = 64 \n","Initial State = 411 \n","Initial State = 226 \n","Initial State = 87 \n","Initial State = 73 \n","Initial State = 394 \n","Initial State = 408 \n","Initial State = 22 \n","Initial State = 452 \n","Initial State = 263 \n","Initial State = 372 \n","Initial State = 26 \n","Initial State = 82 \n","Initial State = 226 \n","Initial State = 181 \n","Initial State = 13 \n","Initial State = 328 \n","Initial State = 442 \n","Initial State = 74 \n","Initial State = 392 \n","Initial State = 346 \n","Initial State = 52 \n","Initial State = 384 \n","Initial State = 164 \n","Initial State = 91 \n","Initial State = 273 \n","Initial State = 188 \n","Initial State = 482 \n","Initial State = 206 \n","Initial State = 241 \n","Initial State = 186 \n","Initial State = 354 \n","Initial State = 368 \n","Initial State = 11 \n","Initial State = 12 \n","Initial State = 253 \n","Initial State = 9 \n","Initial State = 264 \n","Initial State = 163 \n","Initial State = 33 \n","Initial State = 11 \n","Initial State = 44 \n","Initial State = 272 \n","Initial State = 447 \n","Initial State = 167 \n","Initial State = 147 \n","Initial State = 401 \n","Initial State = 328 \n","Initial State = 87 \n","Initial State = 226 \n","Initial State = 466 \n","Initial State = 209 \n","Initial State = 71 \n","Initial State = 147 \n","Initial State = 142 \n","Initial State = 61 \n","Initial State = 229 \n","Initial State = 394 \n","Initial State = 49 \n","Initial State = 113 \n","Initial State = 392 \n","Initial State = 382 \n","Initial State = 334 \n","Initial State = 382 \n","Initial State = 462 \n","Initial State = 189 \n","Initial State = 254 \n","Initial State = 414 \n","Initial State = 46 \n","Initial State = 231 \n","Initial State = 269 \n","Initial State = 409 \n","Initial State = 212 \n","Initial State = 194 \n","Initial State = 167 \n","Initial State = 244 \n","Initial State = 182 \n","Initial State = 86 \n","Initial State = 381 \n","Initial State = 208 \n","Initial State = 313 \n","Initial State = 466 \n","Initial State = 343 \n","Initial State = 329 \n","Initial State = 209 \n","Initial State = 73 \n","Initial State = 432 \n","Initial State = 307 \n","Initial State = 489 \n","Initial State = 328 \n","Initial State = 152 \n","Initial State = 447 \n","Initial State = 32 \n","Initial State = 9 \n","Initial State = 153 \n","Initial State = 402 \n","Initial State = 162 \n","Initial State = 293 \n","Initial State = 391 \n","Initial State = 283 \n","Initial State = 168 \n","Initial State = 123 \n","Initial State = 441 \n","Initial State = 306 \n","Initial State = 132 \n","Initial State = 184 \n","Initial State = 383 \n","Initial State = 327 \n","Initial State = 324 \n","Initial State = 272 \n","Initial State = 163 \n","Initial State = 84 \n","Initial State = 171 \n","Initial State = 102 \n","Initial State = 443 \n","Initial State = 89 \n","Initial State = 263 \n","Initial State = 321 \n","Initial State = 421 \n","Initial State = 429 \n","Initial State = 126 \n","Initial State = 248 \n","Initial State = 303 \n","Initial State = 232 \n","Initial State = 28 \n","Initial State = 304 \n","Initial State = 448 \n","Initial State = 23 \n","Initial State = 241 \n","Initial State = 343 \n","Initial State = 267 \n","Initial State = 388 \n","Initial State = 68 \n","Initial State = 429 \n","Initial State = 443 \n","Initial State = 292 \n","Initial State = 448 \n","Initial State = 364 \n","Initial State = 481 \n","Initial State = 212 \n","Initial State = 304 \n","Initial State = 248 \n","Initial State = 441 \n","Initial State = 51 \n","Initial State = 431 \n","Initial State = 321 \n","Initial State = 71 \n","Initial State = 283 \n","Initial State = 473 \n","Initial State = 181 \n","Initial State = 364 \n","Initial State = 269 \n","Initial State = 424 \n","Initial State = 392 \n","Initial State = 486 \n","Initial State = 248 \n","Initial State = 373 \n","Initial State = 488 \n","Initial State = 253 \n","Initial State = 32 \n","Initial State = 366 \n","Initial State = 294 \n","Initial State = 166 \n","Initial State = 263 \n","Initial State = 28 \n","Initial State = 333 \n","Initial State = 366 \n","Initial State = 71 \n","Initial State = 147 \n","Initial State = 182 \n","Initial State = 142 \n","Initial State = 246 \n","Initial State = 131 \n","Initial State = 448 \n","Initial State = 27 \n","Initial State = 249 \n","Initial State = 394 \n","Initial State = 148 \n","Initial State = 91 \n","Initial State = 69 \n","Initial State = 246 \n","Initial State = 264 \n","Initial State = 129 \n","Initial State = 321 \n","Initial State = 182 \n","Initial State = 424 \n","Initial State = 107 \n","Initial State = 221 \n","Initial State = 91 \n","Initial State = 69 \n","Initial State = 172 \n","Initial State = 121 \n","Initial State = 132 \n","Initial State = 343 \n","Initial State = 134 \n","Initial State = 107 \n","Initial State = 141 \n","Initial State = 44 \n","Initial State = 63 \n","Initial State = 132 \n","Initial State = 386 \n","Initial State = 121 \n","Initial State = 288 \n","Initial State = 347 \n","Initial State = 331 \n","Initial State = 453 \n","Initial State = 27 \n","Initial State = 107 \n","Initial State = 313 \n","Initial State = 371 \n","Initial State = 386 \n","Initial State = 422 \n","Initial State = 481 \n","Initial State = 413 \n","Initial State = 301 \n","Initial State = 301 \n","Initial State = 61 \n","Initial State = 248 \n","Initial State = 351 \n","Initial State = 68 \n","Initial State = 484 \n","Initial State = 284 \n","Initial State = 429 \n","Initial State = 181 \n","Initial State = 203 \n","Initial State = 68 \n","Initial State = 109 \n","Initial State = 89 \n","Initial State = 2 \n","Initial State = 284 \n","Initial State = 373 \n","Initial State = 94 \n","Initial State = 493 \n","Initial State = 487 \n","Initial State = 374 \n","Initial State = 314 \n","Initial State = 141 \n","Initial State = 248 \n","Initial State = 426 \n","Initial State = 147 \n","Initial State = 164 \n","Initial State = 147 \n","Initial State = 242 \n","Initial State = 433 \n","Initial State = 243 \n","Initial State = 361 \n","Initial State = 366 \n","Initial State = 474 \n","Initial State = 451 \n","Initial State = 441 \n","Initial State = 453 \n","Initial State = 409 \n","Initial State = 284 \n","Initial State = 403 \n","Initial State = 21 \n","Initial State = 34 \n","Initial State = 487 \n","Initial State = 67 \n","Initial State = 367 \n","Initial State = 311 \n","Initial State = 201 \n","Initial State = 427 \n","Initial State = 27 \n","Initial State = 448 \n","Initial State = 62 \n","Initial State = 448 \n","Initial State = 72 \n","Initial State = 214 \n","Initial State = 331 \n","Initial State = 402 \n","Initial State = 461 \n","Initial State = 203 \n","Initial State = 309 \n","Initial State = 201 \n","Initial State = 354 \n","Initial State = 304 \n","Initial State = 329 \n","Initial State = 288 \n","Initial State = 151 \n","Initial State = 49 \n","Initial State = 169 \n","Initial State = 308 \n","Initial State = 248 \n","Initial State = 213 \n","Initial State = 207 \n","Initial State = 288 \n","Initial State = 32 \n","Initial State = 106 \n","Initial State = 47 \n","Initial State = 347 \n","Initial State = 389 \n","Initial State = 2 \n","Initial State = 473 \n","Initial State = 66 \n","Initial State = 481 \n","Initial State = 209 \n","Initial State = 402 \n","Initial State = 273 \n","Initial State = 391 \n","Initial State = 284 \n","Initial State = 369 \n","Initial State = 374 \n","Initial State = 172 \n","Initial State = 34 \n","Initial State = 302 \n","Initial State = 192 \n","Initial State = 261 \n","Initial State = 332 \n","Initial State = 483 \n","Initial State = 466 \n","Initial State = 382 \n","Initial State = 131 \n","Initial State = 126 \n","Initial State = 226 \n","Initial State = 461 \n","Initial State = 493 \n","Initial State = 7 \n","Initial State = 307 \n","Initial State = 81 \n","Initial State = 271 \n","Initial State = 213 \n","Initial State = 348 \n","Initial State = 331 \n","Initial State = 333 \n","Initial State = 411 \n","Initial State = 426 \n","Initial State = 186 \n","Initial State = 208 \n","Initial State = 144 \n","Initial State = 261 \n","Initial State = 286 \n","Initial State = 493 \n","Initial State = 222 \n","Initial State = 7 \n","Initial State = 301 \n","Initial State = 73 \n","Initial State = 388 \n","Initial State = 283 \n","Initial State = 89 \n","Initial State = 307 \n","Initial State = 106 \n","Initial State = 13 \n","Initial State = 311 \n","Initial State = 374 \n","Initial State = 128 \n","Initial State = 353 \n","Initial State = 163 \n","Initial State = 468 \n","Initial State = 484 \n","Initial State = 343 \n","Initial State = 167 \n","Initial State = 329 \n","Initial State = 253 \n","Initial State = 32 \n","Initial State = 88 \n","Initial State = 29 \n","Initial State = 167 \n","Initial State = 214 \n","Initial State = 89 \n","Initial State = 342 \n","Initial State = 26 \n","Initial State = 484 \n","Initial State = 192 \n","Initial State = 342 \n","Initial State = 109 \n","Initial State = 304 \n","Initial State = 122 \n","Initial State = 206 \n","Initial State = 228 \n","Initial State = 69 \n","Initial State = 53 \n","Initial State = 211 \n","Initial State = 367 \n","Initial State = 101 \n","Initial State = 363 \n","Initial State = 306 \n","Initial State = 252 \n","Initial State = 293 \n","Initial State = 304 \n","Initial State = 63 \n","Initial State = 93 \n","Initial State = 69 \n","Initial State = 264 \n","Initial State = 409 \n","Initial State = 123 \n","Initial State = 231 \n","Initial State = 469 \n","Initial State = 361 \n","Initial State = 7 \n","Initial State = 13 \n","Initial State = 408 \n","Initial State = 481 \n","Initial State = 229 \n","Initial State = 52 \n","Initial State = 454 \n","Initial State = 112 \n","Initial State = 289 \n","Initial State = 361 \n","Initial State = 466 \n","Initial State = 381 \n","Initial State = 194 \n","Initial State = 164 \n","Initial State = 42 \n","Initial State = 453 \n","Initial State = 209 \n","Initial State = 323 \n","Initial State = 407 \n","Initial State = 343 \n","Initial State = 53 \n","Initial State = 194 \n","Initial State = 184 \n","Initial State = 181 \n","Initial State = 333 \n","Initial State = 168 \n","Initial State = 128 \n","Initial State = 221 \n","Initial State = 72 \n","Initial State = 274 \n","Initial State = 142 \n","Initial State = 364 \n","Initial State = 112 \n","Initial State = 466 \n","Initial State = 334 \n","Initial State = 9 \n","Initial State = 443 \n","Initial State = 244 \n","Initial State = 48 \n","Initial State = 368 \n","Initial State = 252 \n","Initial State = 346 \n","Initial State = 131 \n","Initial State = 164 \n","Initial State = 213 \n","Initial State = 207 \n","Initial State = 232 \n","Initial State = 227 \n","Initial State = 254 \n","Initial State = 426 \n","Initial State = 351 \n","Initial State = 447 \n","Initial State = 273 \n","Initial State = 74 \n","Initial State = 241 \n","Initial State = 69 \n","Initial State = 243 \n","Initial State = 434 \n","Initial State = 132 \n","Initial State = 288 \n","Initial State = 263 \n","Initial State = 347 \n","Initial State = 172 \n","Initial State = 428 \n","Initial State = 167 \n","Initial State = 6 \n","Initial State = 494 \n","Initial State = 493 \n","Initial State = 164 \n","Initial State = 154 \n","Initial State = 9 \n","Initial State = 441 \n","Initial State = 29 \n","Initial State = 493 \n","Initial State = 304 \n","Initial State = 367 \n","Initial State = 441 \n","Initial State = 404 \n","Initial State = 432 \n","Initial State = 133 \n","Initial State = 171 \n","Initial State = 493 \n","Initial State = 204 \n","Initial State = 423 \n","Initial State = 27 \n","Initial State = 306 \n","Initial State = 244 \n","Initial State = 386 \n","Initial State = 34 \n","Initial State = 7 \n","Initial State = 163 \n","Initial State = 254 \n","Initial State = 333 \n","Initial State = 134 \n","Initial State = 428 \n","Initial State = 461 \n","Initial State = 348 \n","Initial State = 424 \n","Initial State = 421 \n","Initial State = 454 \n","Initial State = 154 \n","Initial State = 111 \n","Initial State = 9 \n","Initial State = 482 \n","Initial State = 9 \n","Initial State = 193 \n","Initial State = 301 \n","Initial State = 111 \n","Initial State = 388 \n","Initial State = 342 \n","Initial State = 402 \n","Initial State = 22 \n","Initial State = 12 \n","Initial State = 233 \n","Initial State = 381 \n","Initial State = 389 \n","Initial State = 126 \n","Initial State = 392 \n","Initial State = 263 \n","Initial State = 184 \n","Initial State = 434 \n","Initial State = 128 \n","Initial State = 203 \n","Initial State = 428 \n","Initial State = 424 \n","Initial State = 3 \n","Initial State = 483 \n","Initial State = 132 \n","Initial State = 251 \n","Initial State = 54 \n","Initial State = 14 \n","Initial State = 104 \n","Initial State = 2 \n","Initial State = 26 \n","Initial State = 289 \n","Initial State = 351 \n","Initial State = 283 \n","Initial State = 486 \n","Initial State = 1 \n","Initial State = 103 \n","Initial State = 43 \n","Initial State = 434 \n","Initial State = 342 \n","Initial State = 381 \n","Initial State = 329 \n","Initial State = 88 \n","Initial State = 283 \n","Initial State = 372 \n","Initial State = 324 \n","Initial State = 382 \n","Initial State = 73 \n","Initial State = 292 \n","Initial State = 103 \n","Initial State = 471 \n","Initial State = 12 \n","Initial State = 424 \n","Initial State = 66 \n","Initial State = 488 \n","Initial State = 104 \n","Initial State = 452 \n","Initial State = 144 \n","Initial State = 324 \n","Initial State = 301 \n","Initial State = 194 \n","Initial State = 442 \n","Initial State = 202 \n","Initial State = 484 \n","Initial State = 392 \n","Initial State = 304 \n","Initial State = 491 \n","Initial State = 112 \n","Initial State = 28 \n","Initial State = 224 \n","Initial State = 131 \n","Initial State = 381 \n","Initial State = 424 \n","Initial State = 181 \n","Initial State = 441 \n","Initial State = 134 \n","Initial State = 352 \n","Initial State = 394 \n","Initial State = 33 \n","Initial State = 303 \n","Initial State = 208 \n","Initial State = 144 \n","Initial State = 66 \n","Initial State = 41 \n","Initial State = 412 \n","Initial State = 72 \n","Initial State = 452 \n","Initial State = 114 \n","Initial State = 84 \n","Initial State = 292 \n","Initial State = 191 \n","Initial State = 248 \n","Initial State = 402 \n","Initial State = 228 \n","Initial State = 454 \n","Initial State = 173 \n","Initial State = 52 \n","Initial State = 426 \n","Initial State = 66 \n","Initial State = 184 \n","Initial State = 164 \n","Initial State = 392 \n","Initial State = 492 \n","Initial State = 246 \n","Initial State = 241 \n","Initial State = 143 \n","Initial State = 101 \n","Initial State = 153 \n","Initial State = 223 \n","Initial State = 324 \n","Initial State = 6 \n","Initial State = 246 \n","Initial State = 209 \n","Initial State = 212 \n","Initial State = 363 \n","Initial State = 82 \n","Initial State = 384 \n","Initial State = 268 \n","Initial State = 268 \n","Initial State = 223 \n","Initial State = 164 \n","Initial State = 242 \n","Initial State = 247 \n","Initial State = 8 \n","Initial State = 48 \n","Initial State = 426 \n","Initial State = 442 \n","Initial State = 106 \n","Initial State = 389 \n","Initial State = 401 \n","Initial State = 24 \n","Initial State = 227 \n","Initial State = 84 \n","Initial State = 41 \n","Initial State = 486 \n","Initial State = 108 \n","Initial State = 408 \n","Initial State = 313 \n","Initial State = 474 \n","Initial State = 404 \n","Initial State = 31 \n","Initial State = 127 \n","Initial State = 441 \n","Initial State = 267 \n","Initial State = 467 \n","Initial State = 171 \n","Initial State = 164 \n","Initial State = 121 \n","Initial State = 154 \n","Initial State = 433 \n","Initial State = 193 \n","Initial State = 374 \n","Initial State = 74 \n","Initial State = 208 \n","Initial State = 163 \n","Initial State = 4 \n","Initial State = 369 \n","Initial State = 21 \n","Initial State = 186 \n","Initial State = 166 \n","Initial State = 32 \n","Initial State = 314 \n","Initial State = 266 \n","Initial State = 406 \n","Initial State = 146 \n","Initial State = 408 \n","Initial State = 81 \n","Initial State = 383 \n","Initial State = 81 \n","Initial State = 467 \n","Initial State = 8 \n","Initial State = 142 \n","Initial State = 134 \n","Initial State = 108 \n","Initial State = 132 \n","Initial State = 448 \n","Initial State = 33 \n","Initial State = 72 \n","Initial State = 67 \n","Initial State = 104 \n","Initial State = 326 \n","Initial State = 494 \n","Initial State = 266 \n","Initial State = 222 \n","Initial State = 8 \n","Initial State = 461 \n","Initial State = 74 \n","Initial State = 3 \n","Initial State = 468 \n","Initial State = 121 \n","Initial State = 223 \n","Initial State = 433 \n","Initial State = 402 \n","Initial State = 21 \n","Initial State = 449 \n","Initial State = 328 \n","Initial State = 226 \n","Initial State = 474 \n","Initial State = 174 \n","Initial State = 107 \n","Initial State = 411 \n","Initial State = 54 \n","Initial State = 306 \n","Initial State = 53 \n","Initial State = 209 \n","Initial State = 29 \n","Initial State = 9 \n","Initial State = 354 \n","Initial State = 31 \n","Initial State = 226 \n","Initial State = 444 \n","Initial State = 128 \n","Initial State = 142 \n","Initial State = 123 \n","Initial State = 66 \n","Initial State = 188 \n","Initial State = 448 \n","Initial State = 187 \n","Initial State = 93 \n","Initial State = 286 \n","Initial State = 41 \n","Initial State = 1 \n","Initial State = 81 \n","Initial State = 464 \n","Initial State = 348 \n","Initial State = 201 \n","Initial State = 134 \n","Initial State = 83 \n","Initial State = 72 \n","Initial State = 422 \n","Initial State = 163 \n","Initial State = 189 \n","Initial State = 486 \n","Initial State = 28 \n","Initial State = 12 \n","Initial State = 107 \n","Initial State = 184 \n","Initial State = 381 \n","Initial State = 272 \n","Initial State = 34 \n"]}]},{"cell_type":"code","source":["Q"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLJ6tmFU-v9Q","executionInfo":{"status":"ok","timestamp":1750735525626,"user_tz":-330,"elapsed":15,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"367b366b-818f-4056-ca2d-35e5c9380c55"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n","         0.        ],\n","       [-6.56889478, -6.3       , -6.64152656, -6.3       , 11.        ,\n","        -7.        ],\n","       [-4.63106203, -4.2       , -4.2101871 , -4.2       , 15.        ,\n","        -7.        ],\n","       ...,\n","       [-2.8       , -2.457     , -2.8       , -3.187639  , -7.        ,\n","        -7.        ],\n","       [-4.9       , -4.89600181, -4.9       , -4.7463598 , -7.        ,\n","        -7.        ],\n","       [-1.4       , -1.4       , -1.4       ,  8.89      , -7.        ,\n","        -7.        ]])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# After training, use the Q-table to see how the taxi behaves\n","state = env.reset()\n","done = None\n","\n","\n","\n","\n"],"metadata":{"id":"LMRSJ0NL9UC1","executionInfo":{"status":"ok","timestamp":1750735539285,"user_tz":-330,"elapsed":40,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["while done != True:\n","    action = np.argmax(Q[state])\n","    state, reward, done, info = env.step(action)\n","    print(env.render(mode=\"ansi\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f1jYlYh7-7sU","executionInfo":{"status":"ok","timestamp":1750735557378,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mukesh Kumar","userId":"00664345223903384782"}},"outputId":"ab903928-afc8-45fa-ca9b-04783b9c82fe"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : :\u001b[43m \u001b[0m: |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (West)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[43m \u001b[0m: |\n","|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n","+---------+\n","  (South)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n","+---------+\n","  (South)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |\u001b[42mB\u001b[0m: |\n","+---------+\n","  (Pickup)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : |\u001b[42m_\u001b[0m: |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (North)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : :\u001b[42m_\u001b[0m: |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (North)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : :\u001b[42m_\u001b[0m: : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| :\u001b[42m_\u001b[0m: : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","|\u001b[42m_\u001b[0m: : : : |\n","| | : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (West)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","|\u001b[42m_\u001b[0m| : | : |\n","|\u001b[35mY\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35m\u001b[42mY\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (South)\n","\n","+---------+\n","|R: | : :G|\n","| : | : : |\n","| : : : : |\n","| | : | : |\n","|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n","+---------+\n","  (Dropoff)\n","\n"]}]},{"cell_type":"markdown","source":["# ----------------------------------------------\n","# ✅ SARSA Implementation (On-policy)\n","# ----------------------------------------------"],"metadata":{"id":"HO9SYiAP_dMJ"}},{"cell_type":"code","source":["\n","# Set learning rate (α) and discount factor (γ)\n","alpha = 0.7\n","gamma = 0.7"],"metadata":{"id":"8UXBC9UA9Svl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reset environment and reinitialize Q-table\n","state = env.reset()\n","Q = np.zeros([n_states, n_actions])\n","\n","\n"],"metadata":{"id":"RNvauuTL9Q1U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ε-greedy policy parameter — balances exploration vs exploitation\n","epsilon = 0.1  # 50% chance of exploring\n","\n"],"metadata":{"id":"YbCE5i1e9Phm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to choose action based on ε-greedy policy\n","def choose_action(state):\n","    if np.random.uniform(0, 1) < epsilon:\n","        return env.action_space.sample()  # Exploration\n","    else:\n","        return np.argmax(Q[state, :])     # Exploitation\n","\n","\n","# Cuttoff=0.1 = Exploitation extensively\n","# cutoff = 0.1 = Exploration extensively"],"metadata":{"id":"AsBh0cvE9OWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SARSA update function: uses actual action taken next\n","def learn(state, stateNext, reward, action, actionNext):\n","    predict = Q[state, action]\n","    target = reward + gamma * Q[stateNext, actionNext]\n","    Q[state, action] = Q[state, action] + alpha * (target - predict)\n","\n","\n","\n","## Name comes from the formula in last two lines S-A-R-S-A"],"metadata":{"id":"6tnRz5ja9NJ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train using SARSA\n","total_episodes = 100000\n","\n","for episode in range(total_episodes + 1):\n","    state = env.reset()\n","    action = choose_action(state)\n","    reward = 0\n","\n","    while reward != 20:\n","        stateNext, reward, done, info = env.step(action)\n","        actionNext = choose_action(stateNext)\n","        learn(state, stateNext, reward, action, actionNext)\n","        state = stateNext\n","        action = actionNext"],"metadata":{"id":"GabjVQWG9LV9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Play using the SARSA-trained Q-table (greedy play)\n","state = env.reset()\n","done = None\n","\n","while done != True:\n","    action = np.argmax(Q[state])\n","    state, reward, done, info = env.step(action)\n","    print(env.render(mode=\"ansi\"))\n"],"metadata":{"id":"QSsYZqbt9Ju1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ----------------------------------------------\n","# ❄️ FrozenLake: Optional Extra Assignment\n","# ----------------------------------------------\n","\n","# Load another classic Gym environment\n","env2 = gym.make('FrozenLake-v0')\n","print(env.render(mode=\"ansi\"))\n","\n","env2.observation_space.n  # Number of states in FrozenLake\n","\n","# Manually set state\n","env2.env.s = 4\n","print(env.render(mode=\"ansi\"))"],"metadata":{"id":"qv9KtP-e9HV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HlJis00u9EZk"},"execution_count":null,"outputs":[]}]}