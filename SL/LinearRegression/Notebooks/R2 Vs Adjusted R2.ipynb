{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYD+YGyRi/la2y7IrxH7SO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"9N-snlesqJUH"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["---\n","\n","## **1️. What is R² (R-Squared)?**  \n","R² (coefficient of determination) **measures how well a regression model fits the training data.**  \n","\n","### **Formula:**  \n","$[\n","R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n","]$\n","Where:  \n","- $( SS_{res} )$ = **Sum of Squared Residuals** (Error: difference between actual & predicted values).  \n","- $( SS_{tot} )$ = **Total Sum of Squares** (Variance in the actual data).  \n","\n","### **Interpretation of R²:**  \n","- $( R^2 = 1 )$ → **Perfect fit** (Model explains 100% variance in data).  \n","- $( R^2 = 0 )$ → Model is **no better than just using the mean** of data.  \n","- **Higher R²** → Better model fit.  \n","\n"," **Problem with R²?**  \n","- If we **add more features**, R² **never decreases** (even if those features are useless).  \n","- This leads to **overfitting**, where the model memorizes noise instead of learning patterns.  \n","\n","---\n","\n","## **2️. What is Adjusted R²?**\n","Adjusted R² **penalizes adding unnecessary features** to prevent overfitting.  \n","\n","### **Formula:**\n","$[\n","\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2) \\times (n - 1)}{n - p - 1} \\right)\n","]$\n","Where:  \n","- \\( n \\) = Number of data points (observations).  \n","- \\( p \\) = Number of predictors (independent variables).  \n","\n","### **Key Differences Between R² & Adjusted R²:**  \n","| Metric         | R²                 | Adjusted R²                 |\n","|--------------|------------------|---------------------|\n","| **Effect of Adding Features** | Always increases or stays same | Increases **only if the feature improves the model** |\n","| **Overfitting?** | Yes, encourages it | No, penalizes unnecessary features |\n","| **Best for?** | Checking overall model fit | Comparing models with different numbers of predictors |\n","\n","👉 **If Adjusted R² decreases after adding a feature, that feature is useless!**  \n","\n"],"metadata":{"id":"01NacvexqMo_"}},{"cell_type":"code","source":[],"metadata":{"id":"uR35VbU9qNs9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#How Adjust R2 Works:"],"metadata":{"id":"3JUsTk0lrH0I"}},{"cell_type":"markdown","source":[" The denominator $( (n - p - 1) )$ **always decreases** when we add more features because \\( p \\) (number of predictors) increases.\n","\n","---\n","\n","### **Corrected Explanation**  \n","\n","✅ **Adding a Good Feature:**  \n","- **Numerator (\\( 1 - R^2 \\)) decreases significantly** → making it **very small**.  \n","- **Denominator (\\( n - p - 1 \\)) decreases slightly** (since \\( p \\) increases).  \n","- Since the **numerator shrinks more** than the **denominator**, the fraction gets smaller.  \n","- Result: **\\( 1 - \\) (small fraction) = large Adjusted \\( R^2 \\)** → **Adjusted $( R^2 )$ increases**.  \n","\n","❌ **Adding a Bad Feature:**  \n","- **Numerator ($( 1 - R^2 )$) decreases slightly or remains the same** (because the feature is useless).  \n","- **Denominator (\\( n - p - 1 \\)) still decreases** (since \\( p \\) increases).  \n","- Now, since the **numerator doesn’t shrink much**, but the **denominator still decreases**, the fraction gets larger.  \n","- Result: **\\( 1 - \\) (large fraction) = small Adjusted $( R^2 )$** → **Adjusted $( R^2 )$ decreases**.  \n","\n","---\n","\n","### **Key Insight**  \n","- **Good features shrink the numerator significantly → Adjusted $( R^2 )$ increases.**  \n","- **Bad features don’t shrink the numerator much → Adjusted $( R^2 )$ decreases.**  \n","- **Denominator always decreases, but its impact depends on how much the numerator changes.**  \n","\n"],"metadata":{"id":"TwynD4VaquaX"}},{"cell_type":"code","source":[],"metadata":{"id":"EPi7m712rGDw"},"execution_count":null,"outputs":[]}]}