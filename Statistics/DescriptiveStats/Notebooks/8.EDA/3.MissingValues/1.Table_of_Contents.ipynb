{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzrhh6SXqibY5O53jPXRg7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"GZhymdX9j-NX"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["#Table of Contents"],"metadata":{"id":"nPfxB722kFPh"}},{"cell_type":"markdown","source":["Handling missing values is a crucial step in data preprocessing, as they can significantly impact the performance of machine learning models. Here are several common strategies to handle missing values:\n","\n","### 1. **Remove Missing Values**\n","   - **Remove Rows**: If only a small number of rows have missing values, you can drop them.\n","     ```python\n","     df.dropna(inplace=True)\n","     ```\n","   - **Remove Columns**: If an entire column has too many missing values, you can drop the column.\n","     ```python\n","     df.dropna(axis=1, inplace=True)\n","     ```\n","\n","### 2. **Impute Missing Values**\n","   - **Mean Imputation**: Replace missing values with the mean of the column.\n","     ```python\n","     df['column'].fillna(df['column'].mean(), inplace=True)\n","     ```\n","   - **Median Imputation**: Use the median instead of the mean, which is more robust to outliers.\n","     ```python\n","     df['column'].fillna(df['column'].median(), inplace=True)\n","     ```\n","   - **Mode Imputation**: Use the mode for categorical data.\n","     ```python\n","     df['column'].fillna(df['column'].mode()[0], inplace=True)\n","     ```\n","\n","### 3. **Interpolation**\n","   - Use interpolation techniques to estimate missing values based on other data points.\n","     ```python\n","     df['column'].interpolate(method='linear', inplace=True)\n","     ```\n","\n","### 4. **Imputation Using k-Nearest Neighbors (KNN)**\n","   - Impute missing values based on the values of the k-nearest neighbors.\n","     ```python\n","     from sklearn.impute import KNNImputer\n","     imputer = KNNImputer(n_neighbors=5)\n","     df_imputed = imputer.fit_transform(df)\n","     ```\n","\n","### 5. **Using Algorithms That Handle Missing Values**\n","   - Some machine learning algorithms can handle missing values internally, such as:\n","     - **XGBoost**\n","     - **LightGBM**\n","     - **CatBoost**\n","\n","### 6. **Create a Missing Indicator**\n","   - Add a binary indicator column to capture missingness as a feature.\n","     ```python\n","     df['column_missing'] = df['column'].isnull().astype(int)\n","     ```\n","\n","### 7. **Imputation Using Regression**\n","   - Predict missing values using regression models based on other features.\n","     ```python\n","     from sklearn.linear_model import LinearRegression\n","     # Fit regression on non-missing data and predict missing values.\n","     ```\n","\n","### 8. **Custom Imputation**\n","   - Use domain-specific knowledge to fill missing values with meaningful defaults.\n","\n","### 9. **Multiple Imputation**\n","   - Perform multiple imputations to account for the uncertainty of missing data.\n","     ```python\n","     from sklearn.experimental import enable_iterative_imputer\n","     from sklearn.impute import IterativeImputer\n","     imputer = IterativeImputer()\n","     df_imputed = imputer.fit_transform(df)\n","     ```\n","\n","### 10. **Leave Missing Values as Is (If Supported)**\n","   - Some algorithms, like tree-based methods, can handle missing values directly.\n","\n","### Choosing the Right Method:\n","- **Small dataset**: Imputation to avoid losing data.\n","- **Large dataset**: Removal may not impact the model significantly.\n","- **Numeric data**: Mean, median, or interpolation.\n","- **Categorical data**: Mode or custom value.\n","- **Predictive models**: Use advanced methods like KNN or multiple imputations.\n","\n"],"metadata":{"id":"8kg20PtRj-p9"}},{"cell_type":"code","source":[],"metadata":{"id":"L6EDQqeleGBY"},"execution_count":null,"outputs":[]}]}